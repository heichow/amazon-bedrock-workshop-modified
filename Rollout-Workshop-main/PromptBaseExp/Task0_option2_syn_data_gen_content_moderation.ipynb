{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a0175c-d502-4962-ae02-a92f613edd41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea4fe2-737b-4599-b2ab-6b29241aef8a",
   "metadata": {},
   "source": [
    "In this notebook, we are going to generate some synthetic data that represents some of the most popular CX use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481660af-e781-4695-8213-ce59ffd354c5",
   "metadata": {},
   "source": [
    "### Environment Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6312bc6-b100-4b4f-87c9-1155e078aa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "apache-beam 2.52.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.2 which is incompatible.\n",
      "docker-compose 1.29.2 requires jsonschema<4,>=2.5.1, but you have jsonschema 4.20.0 which is incompatible.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.6.0 which is incompatible.\n",
      "nemoguardrails 0.5.0 requires langchain==0.0.251, but you have langchain 0.0.309 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.1.1 which is incompatible.\n",
      "pyasn1-modules 0.2.8 requires pyasn1<0.5.0,>=0.4.6, but you have pyasn1 0.5.1 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.14.0 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.0a6 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.14.0 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Update SDK and Install related libraries\n",
    "# You can ignore the error related to installation\n",
    "%pip install --quiet --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n",
    "\n",
    "%pip install --quiet langchain==0.0.309 \"transformers>=4.24,<5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab65cd5-3ce8-4c78-ada1-6ea0c1f1c357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "# Set up IAM\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0294d-b72b-429c-84c6-52f6afe22b0a",
   "metadata": {},
   "source": [
    "### Raw Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eabf1a-7b10-47ae-9401-44322f35d249",
   "metadata": {},
   "source": [
    "The orginal dataset contains multiple different languages, which significantly increases the evaluation difficulty.  Therefore I have used the prompt below to translate and re-generate data for this workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c491de74-2612-4623-91dd-ad5220e14968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_translate_and_generate = '''\n",
    "\n",
    "Human: you are a translation assistant. below is a gaming chat history in <history_chat>.  \n",
    "Your task is to translate the history into English while following the instructions in <instructions>.\n",
    "\n",
    "here is the chat history in <history_chat>:\n",
    "<history_chat>\n",
    "{input_chat}\n",
    "</history_chat>\n",
    "\n",
    "here are the requirements for translation in <instructions>:\n",
    "<instructions>\n",
    "1, If the chat is not in English, Spanish, Traditional Chinese or Simplified Chinese, respond with 'No Translation' and do not do translation\n",
    "2, If the chat is in English, translate into Simplified Chinese\n",
    "3, If the chat is in Spanish, translate into English\n",
    "4, If the chat is in Traditional Chinese or Simplified Chinese, translate into English\n",
    "5, Keep in mind that the translation should mimic real conversation between players of MOBA Game, and you should try your best to keep all the cursing and slang used.\n",
    "6, Write the output in chat-like format, and use identifiers like \"A:, B:, C: \" to help clarify the conversation \n",
    "7, Please put your translation in <answer></answer> XML tags.\n",
    "</instructions>\n",
    "\n",
    "Assistant:\n",
    "<answer>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a399cd-9d1c-43b7-93a9-f7f0fd16d5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">input</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>No Translation\\n\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>C: estate \\nD: 1/estos 4 de en formar una escu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input                                                               \n",
       "   count unique                                                top freq\n",
       "gt                                                                     \n",
       "0    156    154                                 No Translation\\n\\n    3\n",
       "1    159    159  C: estate \\nD: 1/estos 4 de en formar una escu...    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Sample data you just generated from Task0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw = pd.read_csv('lxq_cm_gen_raw.csv')\n",
    "raw.groupby('gt').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd2dabab-67fd-440e-8bb0-991ae7a0570a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12507/1694031717.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_valid[\"gt\"] = np.where(raw_valid[\"gt\"] == 1, 'T', 'F')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1: So easy, abc\\n</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B: Okay go mid\\nA: See a cs\\nB: Okay\\nA: I'm m...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B: 谁需要游走英雄 组队\\nC: 谁需要游走英雄和法师 组队\\nD: -1 邀请\\nE: ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B:哈哈哈  \\nC:我高兴\\nD:52533\\nE:哈哈哈\\nF:哈哈哈\\nG:1/哭得更...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B: Just ask your dad \\nC: You don't need to wi...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>\\n/A: 我选了埃斯特斯\\n/B: 我选了埃迪斯\\n/B: 刚进游戏的菜鸟。废物们。\\n/...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>B: bn yak alsan\\nC: 1/req\\nD: b90k ya b90k aj\\...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>B: 黄金就5千  \\nA: 怎么了?  \\nB: 我只有一个洞  \\nA: 解释一下亲爱的...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>B: 多少钱?\\nC: 你的大脑值这么多钱吗?  \\nD: 真没办法。\\n</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>B: 好了,别提了\\nC: 说得对,我们都该努把力\\nD: 要不然就跪了,被Selena,B...</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input gt\n",
       "0                                    1: So easy, abc\\n  F\n",
       "1    B: Okay go mid\\nA: See a cs\\nB: Okay\\nA: I'm m...  F\n",
       "2    B: 谁需要游走英雄 组队\\nC: 谁需要游走英雄和法师 组队\\nD: -1 邀请\\nE: ...  F\n",
       "4    B:哈哈哈  \\nC:我高兴\\nD:52533\\nE:哈哈哈\\nF:哈哈哈\\nG:1/哭得更...  F\n",
       "5    B: Just ask your dad \\nC: You don't need to wi...  F\n",
       "..                                                 ... ..\n",
       "495  \\n/A: 我选了埃斯特斯\\n/B: 我选了埃迪斯\\n/B: 刚进游戏的菜鸟。废物们。\\n/...  T\n",
       "497  B: bn yak alsan\\nC: 1/req\\nD: b90k ya b90k aj\\...  T\n",
       "499  B: 黄金就5千  \\nA: 怎么了?  \\nB: 我只有一个洞  \\nA: 解释一下亲爱的...  T\n",
       "500              B: 多少钱?\\nC: 你的大脑值这么多钱吗?  \\nD: 真没办法。\\n  T\n",
       "503  B: 好了,别提了\\nC: 说得对,我们都该努把力\\nD: 要不然就跪了,被Selena,B...  T\n",
       "\n",
       "[294 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "raw_dropna = raw.dropna()\n",
    "raw_valid = raw_dropna[raw_dropna[\"input\"].str.contains(\"No Translation\") == False] \n",
    "raw_valid[\"gt\"] = np.where(raw_valid[\"gt\"] == 1, 'T', 'F')\n",
    "raw_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8796e7-2efb-4835-a44e-a5445a9c01c1",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation - Compare Results from Different Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5adeaa57-d9c5-4da1-85a9-de75685d63a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Up Claude Parameters\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":1,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                    client = boto3_bedrock, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b48fe-86cd-4756-b937-13f6824efe60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c4396c-bfc1-4ab5-9823-d9963a2ffd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt for generating synthetic data\n",
    "## Base\n",
    "p_base = '''\n",
    "\\n\\nHuman:\n",
    "你是一个数据生成员. 你的目标是按照<instructions>中的要求改写<example>中的给定MOBA游戏玩家对话对话.\n",
    "\n",
    "重写要求<instructions>\n",
    "0，用同一个语种改写\n",
    "1，每次生成三个不同的对话\n",
    "2，改写后的对话含义不能变，不要增加额外的信息，不要添油加醋，不要发挥想象\n",
    "3，改写包括语序改变，换词\n",
    "4，改写前后对话的长短要相似，语义要通顺，说话要更拟人，更随便，更口头\n",
    "</instructions>\n",
    "\n",
    "<examples>\n",
    "B: 什么角色?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?职业或者位置?\n",
    "C: 跟着这个菜鸟ADC, 把他当腊肉扒皮。\n",
    "</examples>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "\n",
    "## Now assume a customer that's upset and impatient \n",
    "p_trashtalk = '''\n",
    "\\n\\nHuman:\n",
    "你是一个数据生成员. 你的目标是按照<instructions>中的要求改写<example>中的给定MOBA游戏玩家对话对话.\n",
    "\n",
    "重写要求<instructions>\n",
    "0，用同一个语种改写\n",
    "1，每次生成三个不同的对话\n",
    "2，改写后的对话含义不能变，不要增加额外的信息，不要添油加醋，不要发挥想象\n",
    "3，改写包括语序改变，换词\n",
    "4，改写前后对话的长短要相似，语义要通顺，说话要更拟人，更随便，更口头，但是对话要更具讽刺性和攻击性，可适量增加一些经济场合常见的垃圾话（trash talk）\n",
    "</instructions>\n",
    "\n",
    "<examples>\n",
    "B: 什么角色?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?职业或者位置?\n",
    "C: 跟着这个菜鸟ADC, 把他当腊肉扒皮。\n",
    "</examples>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "\n",
    "## Now assume a customer that's chatty and confused\n",
    "p_young = '''\n",
    "\\n\\nHuman:\n",
    "你是一个数据生成员. 你的目标是按照<instructions>中的要求改写<example>中的给定MOBA游戏玩家对话对话.\n",
    "\n",
    "重写要求<instructions>\n",
    "0，用同一个语种改写\n",
    "1，每次生成三个不同的对话\n",
    "2，改写后的对话含义不能变，不要增加额外的信息，不要添油加醋，不要发挥想象\n",
    "3，改写包括语序改变，换词\n",
    "4，改写前后对话的长短要相似，语义要通顺，说话要更拟人，更随便，更口头，可适当增加一些社交媒体上年轻人常用的俚语\n",
    "</instructions>\n",
    "\n",
    "<examples>\n",
    "B: 什么角色?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?职业或者位置?\n",
    "C: 跟着这个菜鸟ADC, 把他当腊肉扒皮。\n",
    "</examples>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "\n",
    "## Now try translating the data into other languages.  This is specially useful when the Cx has insufficient data when localizing.\n",
    "p_translate = '''\n",
    "\\n\\nHuman:\n",
    "你是一个数据生成员. 你的目标是按照<instructions>中的要求改写<example>中的给定MOBA游戏玩家对话对话.\n",
    "\n",
    "重写要求<instructions>\n",
    "1，每次生成四个不同语种的对话：1个英文，1个符合中国大陆语言习惯，1个符合台湾语言习惯，1个符合香港语言习惯\n",
    "2，改写后的对话含义不能变，不要增加额外的信息，不要添油加醋，不要发挥想象\n",
    "3，改写包括语序改变，换词\n",
    "4，改写前后对话的长短要相似，语义要通顺，说话要更拟人，更随便，更口头\n",
    "</instructions>\n",
    "\n",
    "<examples>\n",
    "B: 什么角色?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?\n",
    "A: 你选了啥?职业或者位置?\n",
    "C: 跟着这个菜鸟ADC, 把他当腊肉扒皮。\n",
    "</examples>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d402f7-5bdd-4c41-a519-599a7ff8cb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate your LLM execution time\n",
    "import time\n",
    "\n",
    "def timer_llm(prompt, if_print=1):\n",
    "    start_time = time.time()\n",
    "    response = textgen_llm(prompt)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    if if_print == 1:\n",
    "        print(\"----------------------------------------- OutPut -----------------------------------------\")\n",
    "        print(\"Elapsed time: \", elapsed_time, \"seconds\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6dc0589-148e-4238-8817-fde35739b744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------- OutPut -----------------------------------------\n",
      "Elapsed time:  7.312505722045898 seconds\n",
      "\n",
      "A: 哥们,选哪个角色啊?\n",
      "B: 你挑了哪个英雄?ADC还是辅助?\n",
      "C: 这个ADC太菜了,跟着他打怪简直要命。\n",
      "A: 兄弟,你选了什么位置?\n",
      "B: 你用什么英雄啊?打野还是中单?\n",
      "C: 这个ADC操作太烂了,跟他打线跟虐待一样。\n",
      "A: 卧槽,你选什么角色啊?\n",
      "B: 你用啥英雄啊?上单还是打野?\n",
      "C: 我去,这个ADC烂的要命,我辅助他简直受罪。\n",
      "----------------------------------------- OutPut -----------------------------------------\n",
      "Elapsed time:  3.940587043762207 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# p_trashtalk\u001b[39;00m\n\u001b[1;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m timer_llm(p_trashtalk)\n\u001b[0;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m response[\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     12\u001b[0m print_ww(result)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# p_young\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "# Compare Results\n",
    "import time\n",
    "\n",
    "# p_base\n",
    "response = timer_llm(p_base)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)\n",
    "\n",
    "# p_trashtalk\n",
    "response = timer_llm(p_trashtalk)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)\n",
    "\n",
    "# p_young\n",
    "response = timer_llm(p_young)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)\n",
    "\n",
    "# p_translate\n",
    "response = timer_llm(p_translate)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b9aa1-d25f-4b60-afce-027b20c833fa",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation - Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861fc3b-304c-42e4-b8ab-953f74c16153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch generation\n",
    "## sample 10% observations from each category \n",
    "sample_df = raw_valid.groupby(\"gt\").sample(frac = 0.1, random_state=1)\n",
    "sample_df.groupby('gt').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21191dae-9ad0-4492-ac9d-b3d7cc70da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt for batch generation\n",
    "# below is an example\n",
    "p_batch_gen_example = '''\n",
    "\\n\\nHuman:\n",
    "你是一个数据生成员. 你的目标是按照<instructions>中的要求改写<example>中的给定MOBA游戏玩家对话.\n",
    "\n",
    "重写要求<instructions>\n",
    "1，每次生成两个不同的游戏对话改写\n",
    "2，改写后的对话主要含义和情绪不能变，不要增加额外的信息，不要添油加醋\n",
    "3，改写包括语序改变，换词\n",
    "4，改写前后对话的长短要相似，语义要通顺，说话要更拟人，更随便，更口头\n",
    "5，综合上述要评估生成结果，选择最符合上述要求的一条写入<best>\n",
    "</instructions>\n",
    "\n",
    "<examples>\n",
    "{input_data}\n",
    "</examples>\n",
    "\n",
    "<output_format>\n",
    "五个备选：\n",
    "<best>\n",
    "</best>\n",
    "</output_format>\n",
    "\n",
    "\\n\\nAssistant:\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffd1ec-77d2-4747-a9ec-389cb95dc66a",
   "metadata": {},
   "source": [
    "#### Now write your own prompt <br>\n",
    "\n",
    "<b>Requirements: </b><br>\n",
    "You want to generate several re-writes and choose the best one, and write into \"\\<best>\\</best>\" tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0764c8-62db-454e-9600-7ff9734c1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_batch_gen = '''\n",
    "\\n\\nHuman:\n",
    "你是一个数据生成员. 你的目标是按照<instructions>中的要求改写<example>中的给定MOBA游戏玩家对话.\n",
    "\n",
    "重写要求<instructions>\n",
    "{{WRITE YOUR OWN INSTRUCTIONS}}\n",
    "</instructions>\n",
    "\n",
    "<examples>\n",
    "{{PLACEHOLDER FOR INPUT EXAMPLES}}\n",
    "</examples>\n",
    "\n",
    "<output_format>\n",
    "{{REQUIREMENTS/EXAMPLES FOR OUTPUT FORMAT}}\n",
    "</output_format>\n",
    "\n",
    "\\n\\nAssistant:\\n\n",
    "'''\n",
    "\n",
    "## generate synthetic data from the sample\n",
    "syn_data = sample_df.copy()\n",
    "for i in range(sample_df.shape[0]):\n",
    "    symptom = sample_df.iloc[i][0]\n",
    "    prompt = p_batch_gen.format(input_data = symptom)\n",
    "    response = timer_llm(prompt, 0)\n",
    "    result_details = response[response.index('\\n')+1:]\n",
    "    if '<best>' in result_details and '</best>' in result_details:\n",
    "        result_best = result_details[result_details.index('<best>')+6:result_details.index('</best>')]\n",
    "    else:\n",
    "        result_best = 'No <best> found'\n",
    "    syn_data.iloc[i][0] = result_best\n",
    "    #print_ww(result_details)\n",
    "    #print(\"Given Sample: \", symptom)\n",
    "    #print(\"Best Generated Sample: \", result_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ebe11-31c8-42c9-8df8-f499b71928fd",
   "metadata": {},
   "source": [
    "### Save the Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bb6c1-7aa7-4248-a893-e5376a686e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust your output file name, for example: heather_voc_gen_.csv\n",
    "syn_data.to_csv('REPLACE_YOUR_NAME_HERE_cm_gen.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8b455-fd74-4373-9a2f-4dc1a00805d7",
   "metadata": {},
   "source": [
    "# <font color=red>Assignment: Save the Generated Data and Upload it to the WorkDoc<font color=red>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6287c3b-6f2a-4ec3-b9f2-4f4f74c1b819",
   "metadata": {},
   "source": [
    "https://amazon.awsapps.com/workdocs-preview/index.html#/folder/f573754f5bdde41d63543d02eb277bee333e322238ad051755a02e050b8513ce"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
