{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a071de7a-a8ab-44ca-936b-472ebc0c8df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VOC - Customer Service Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a4979-0fa7-4c04-88a2-126f64639fff",
   "metadata": {},
   "source": [
    "In this notebook, we will look at the Customer Service Analysis use case, and go through the general process of prompt optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66977f9f-e19b-4a34-86da-77fd024d1b58",
   "metadata": {},
   "source": [
    "### Step 0: Environment Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c5140-cb74-4ecc-beda-5be0db74a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update SDK and Install related libraries\n",
    "# You can ignore the error related to installation\n",
    "%pip install --quiet --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n",
    "\n",
    "%pip install --quiet langchain==0.0.309 \"transformers>=4.24,<5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1aa483-6f5b-4459-a9e1-2fe815c184d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up IAM\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4899f5-7fdb-4509-88de-87fd44a11b6c",
   "metadata": {},
   "source": [
    "### Raw Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b666c7-2c5f-4a0d-bb6f-d45aa725aff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the Sample data you just generated from Task0\n",
    "import pandas as pd\n",
    "raw = pd.read_csv('yourname_voc_gen_.csv')\n",
    "raw.groupby('故障分类').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8560d09-a788-4ba6-9ae4-59c574698c27",
   "metadata": {},
   "source": [
    "### Step1: Prompt Template Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d4e767-eaf7-45c1-bc4c-c9888dd10951",
   "metadata": {},
   "source": [
    "In this step, you will learn how to write a base prompt for classification.  <br>\n",
    "\n",
    "<b>Trick:<br></b>\n",
    "\n",
    "1, Try changing the temperature level: <br>\n",
    "Temperature is a parameter that controls the randomness of a model's predictions during generation. Higher temperature leads to more creative samples that enable multiple variations in phrasing (and in the case of fiction, variation in answers as well), while lower temperature leads to more conservative samples that stick to the most-probable phrasing and answer. Adjusting the temperature is a way to encourage a language model to explore rare, uncommon, or surprising next words or sequences, rather than only selecting the most likely predictions. Claude Slackbot uses a non-zero temperature when generating responses, that allow some variation in its answers.\n",
    "\n",
    "2, Try generating multiple times and select the best answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf1311-8dd8-4d59-88a5-2ff7136dfd4f",
   "metadata": {},
   "source": [
    "#### <font color=\"purple\">Using Claude to Generate a Prompt Template for Classification from Scratch</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570e54b-125b-43f2-a908-593e22a7096d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Up Claude Parameters\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":1,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                    client = boto3_bedrock, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )\n",
    "\n",
    "# Func used to call llm while calculating execution time.  Set if_print to 0 to avoid printing.\n",
    "import time\n",
    "def timer_llm(prompt, if_print = 1):\n",
    "    start_time = time.time()\n",
    "    response = textgen_llm(prompt)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    if if_print == 1:\n",
    "        print(\"----------------------------------------- OutPut -----------------------------------------\")\n",
    "        print(\"Elapsed time: \", elapsed_time, \"seconds\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8c5cf-c8d5-46c7-ad25-6a73b13106c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This prompt is used to generate a classification prompt template\n",
    "p_p_gen = '''\n",
    "\\n\\nHuman:\n",
    "你是一个prompt书写助手，你的任务是按照<instructions>里面的要求帮助我写一个用作客服分类的提示词模版。\n",
    "\n",
    "<instructions>\n",
    "1, 该prompt模版将用来进行客服问题分类\n",
    "2，8个客服问题分类在<cate>中\n",
    "<cate>\n",
    "备件/商务咨询\n",
    "床\n",
    "扫描架\n",
    "扫描问题\n",
    "探测器\n",
    "操作台\n",
    "球管/高压\n",
    "无法判断\n",
    "</cate>\n",
    "3，输出prompt模版应该包括三个部分:\n",
    "<task>任务</task>\n",
    "<requirements>任务要求</requirements>\n",
    "<output_format>输出格式要求</output_format>\n",
    "</intructions>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "\n",
    "response = timer_llm(p_p_gen)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1b6a6-948b-4be7-8460-4a56c456143c",
   "metadata": {},
   "source": [
    "#### <font color=\"purple\">Alternatively, Try Using the Suggested Claude Template for General Classification Tasks as a Starting Point</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6759e07-1186-4e44-84ae-37af24bd97f4",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/u/0/d/1TlOKgJe4gziNBVSL5FDjRvZI-f7oHQUF6deQkcM6rBk/htmlview?pli=1#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96281cf4-585d-453f-a471-2443086cc88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This prompt is used to re-write/optimize a base prompt\n",
    "p_claude_for_classification = '''\n",
    "You are a customer service agent that is classifying emails by type. I want you to give your answer and then explain it.\n",
    "\n",
    "How would you categorize this email?\n",
    "<email>\n",
    "{{EMAIL}}\n",
    "</email>\n",
    "\n",
    "Categories are:\n",
    "(A) Pre-sale question\n",
    "(B) Broken or defective item\n",
    "(C) Billing question\n",
    "(D) Other (please explain)\n",
    "\n",
    "'''\n",
    "\n",
    "p_p_gen2 = '''\n",
    "\\n\\nHuman:\n",
    "你是一个prompt改写助理，你的任务是按照<instructions>里面的要求，根据给出的基础prompt模版<given_prompt_template>改写一个用作客服分类的提示词模版。\n",
    "\n",
    "这里是原始的prompt模型<given_prompt_template>\n",
    "{claude_pe_template}\n",
    "</given_prompt_template>\n",
    "\n",
    "<instructions>\n",
    "1, 改写后的提示词模版应全部为简体中文\n",
    "2，任务是根据客服描述定位客服问题分类\n",
    "3，输入为客服描述不是邮件\n",
    "4，8个客服问题分类在<cate>中\n",
    "<cate>\n",
    "备件/商务咨询\n",
    "床\n",
    "扫描架\n",
    "扫描问题\n",
    "探测器\n",
    "操作台\n",
    "球管/高压\n",
    "无法判断\n",
    "5，think step by step\n",
    "</cate>\n",
    "</intructions>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "prompt = p_p_gen2.format(claude_pe_template=p_claude_for_classification)\n",
    "response = timer_llm(prompt)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89626a-de84-4e21-a30b-e128eb9dcc6d",
   "metadata": {},
   "source": [
    "### Step2: Using Claude to Generate Classification Rules/Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4396c-bfc1-4ab5-9823-d9963a2ffd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feed all the data to Claude and ask it to generate rules for classification\n",
    "examples = ''\n",
    "for i in range(raw.shape[0]):\n",
    "    symptom = raw.iloc[i][0]\n",
    "    cla = raw.iloc[i][1]\n",
    "    eg_tmp = '问题： ' + symptom + '\\n' + '分类： ' + cla + '\\n\\n'\n",
    "    examples = examples + eg_tmp\n",
    "#print(examples)\n",
    "\n",
    "p_rule = '''\n",
    "\\n\\nHuman: 你是一名客服人员，请从下面的examples中总结出每个故障分类的规则:\\n\n",
    "<examples>\\n\n",
    "{input_examples}\n",
    "\\n</examples>\\n\n",
    "并请用下面的format作答：\\n\n",
    "<format>\\n\n",
    "(A) 备件/商务咨询：\n",
    "(B) 床：\n",
    "(C) 扫描架：\n",
    "(D) 扫描问题：\n",
    "(E) 探测器：\n",
    "(F) 操作台：\n",
    "(G) 球管/高压：\n",
    "(H) 无法判断：\n",
    "\\n</format>\\n\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "\n",
    "prompt = p_rule.format(input_examples=examples)\n",
    "response = timer_llm(prompt)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878bc0c-58fa-449d-af8b-7d4b149c2b49",
   "metadata": {},
   "source": [
    "### Step3: Assemble Base Prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003149f-9f56-4563-b47f-9cd4d0279cee",
   "metadata": {},
   "source": [
    "Manually assemble your prompt based on results from Step1 and Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e096af-c6db-42db-a10e-c09ba3b75238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is an example\n",
    "p_base_example = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要根据分类要求<instructions>对客户的描述<description>对客服问题进行分类。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{input_description}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "1， 将上方<description>中描述的客服问题分类到以下8个类别中\n",
    "备件/商务咨询: 提到物品价格,搬迁,流程等与商务有关的问题。\n",
    "床: 提到床无法移动,出入不便等与床操作相关的问题。\n",
    "扫描架: 提到gantry, revolution等与扫描架相关的关键词。\n",
    "扫描问题: 提到无法获得图像,出现伪影,硬件错误等直接与扫描质量相关的问题。\n",
    "探测器: 提到探测器温度,指针移动产生假影等与探测器相关的问题。\n",
    "操作台: 提到开机失败,工作站不能使用,传不进PACS等与操作台相关的问题。\n",
    "球管/高压: 提到球管故障,报错,异响等与球管和高压相关的问题。\n",
    "无法判断: 对于一些语句信息不足无法判断分类的问题。\n",
    "2，每个问题只选择一个最适合的类别\n",
    "3，如果无法判断类别,则选择“无法判断”\n",
    "4，必须严格用<example>中给出的样例格式回复, 输出结果中必须包含：<answer></answer>和<reasoning></reasoning>：\n",
    "<example>\n",
    "<answer>：\n",
    "操作台\n",
    "</answer>\n",
    "<reasoning>：\n",
    "根据分类规则工作站不能使用，死机，黑屏属于操作台故障分类。\n",
    "</reasoning>：\n",
    "</example>\n",
    "<instructions>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "<answer>分类结果</answer>\n",
    "<reasoning>分析</reasoning>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c08bf-3cda-4a8f-af77-e2c90120e5a7",
   "metadata": {},
   "source": [
    "#### Now write your own prompt <br>\n",
    "\n",
    "<b>Requirements: </b><br>\n",
    "1, Put classification answer into \"\\<answer>\\</answer>\" tags in the response <br>\n",
    "2, Put reasoning into \"\\<reasoning>\\</reasoning>\" tags in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38417a-5768-47ab-b723-f16e5bf5727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write your own base prompt for batch testing\n",
    "p_base = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要根据分类要求<instructions>对客户的描述<description>对客服问题进行分类。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{{PLACEHOLDER FOR THE INPUT}}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "{{YOUR OWN INSTRUCTIONS: TAKE PREVIOUS RESULTS AS REFERENCES}}\n",
    "</instructions>\n",
    "\n",
    "<output_format>中是输出格式要求：\n",
    "<output_format>\n",
    "{{YOUR OWN OUTPUT FORMAT REQUIREMENTS/EXAMPLES}}\n",
    "</output_format>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4eb93-1485-4774-ab0a-3379939dbd10",
   "metadata": {},
   "source": [
    "### Step4: Batch Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f9a8b-7f48-40f5-b78a-1f89c2f86c83",
   "metadata": {},
   "source": [
    "In this step, you will learn how to perform batch testing and analyze results.  <br>\n",
    "\n",
    "<b>Trick:<br></b>\n",
    "\n",
    "1, You want to re-set some of the parameters to help stablize the testing results.  For example, you want to set temperature to 0 from this point. <br>\n",
    "\n",
    "2, It will take roughly 3-5 minutes to finish batch tesing for the entire test set of size 50: the processing time depends on your prompt complexicity, input length, and output length (it may try to generate a long analysis).  Therefore, it is also advised to set a desired output length either within the prompt itself or through the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69edc80-87c4-4640-9ce6-a2ed5f5d9d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# func used to do batch testing\n",
    "# input_df: test dataset df\n",
    "# input_prompt: prompt template used to do batch testing\n",
    "# output_file_name: for example, \"xxx.csv\"\n",
    "def mybatchtest(input_df, input_prompt, output_file_name):\n",
    "    df = input_df.copy()\n",
    "    df['预测分类'] = ''\n",
    "    df['预测分析'] = ''\n",
    "    df['预测结果'] = ''\n",
    "    for i in range(df.shape[0]):\n",
    "    #for i in range(3):\n",
    "        symptom = df.iloc[i][0]\n",
    "        prompt = input_prompt.format(input_description = symptom)\n",
    "        response = timer_llm(prompt, if_print = 0)\n",
    "        result = response[response.index('\\n')+1:]\n",
    "        #print_ww(result)\n",
    "        if  '<answer>' in result and '</answer>' in result:\n",
    "            answer = result[result.index('<answer>')+7:result.index('</answer>')].replace('\\n','').replace('>','')\n",
    "        else:   \n",
    "            answer = result\n",
    "        if  '<reasoning>' in result and '</reasoning>' in result:\n",
    "            reasoning = result[result.index('<reasoning>')+11:result.index('</reasoning>')].replace('\\n','').replace('>','')\n",
    "        else:   \n",
    "            reasoning = 'tbd'\n",
    "        #print(answer)\n",
    "        #print(reasoning)\n",
    "\n",
    "        gt = symptom = df.iloc[i][1]\n",
    "        if gt in answer:\n",
    "            pred = 'T'\n",
    "        else:\n",
    "            pred = 'F'\n",
    "\n",
    "        df.iat[i,2] = answer\n",
    "        df.iat[i,3] = reasoning\n",
    "        df.iat[i,4] = pred\n",
    "    # save results\n",
    "    df.to_csv(output_file_name,index = False)\n",
    "    return df\n",
    "\n",
    "# func used to do batch testing with resampling\n",
    "# input_df: test dataset df\n",
    "# input_prompt_base: prompt base template used to do batch testing\n",
    "# input_prompt: prompt template used to do evaluation for resampled results\n",
    "# resample_times: the number of times to resample\n",
    "# output_file_name: for example, \"xxx.csv\"\n",
    "def mybatchtest_resample(input_df, input_prompt_base, input_prompt, output_file_name, resample_times = 3):\n",
    "    df = input_df.copy()\n",
    "    df['预测分类'] = ''\n",
    "    df['预测分析'] = ''\n",
    "    df['预测结果'] = ''\n",
    "    for i in range(df.shape[0]):\n",
    "    #for i in range(3):\n",
    "        symptom = df.iloc[i][0]\n",
    "        prompt_base = input_prompt_base.format(input_description = symptom)\n",
    "        \n",
    "        answers = ''\n",
    "        for j in range(resample_times):\n",
    "            response = timer_llm(prompt_base, if_print = 0)\n",
    "            result = response[response.index('\\n')+1:]\n",
    "            if  '<answer>' in result and '</answer>' in result:\n",
    "                answer = result[result.index('<answer>')+7:result.index('</answer>')].replace('\\n','').replace('>','')\n",
    "            else:\n",
    "                answer = result\n",
    "            if  '<reasoning>' in result and '</reasoning>' in result:\n",
    "                reasoning = result[result.index('<reasoning>')+11:result.index('</reasoning>')].replace('\\n','').replace('>','')\n",
    "            else:\n",
    "                reasoning = 'tbd'\n",
    "            answer_tmp = 'id' + str(i) +':\\n' + '<answer>： ' + answer + '<\\answer>\\n' + '<reasoning>： ' + reasoning + '<\\reasoning>\\n\\n' \n",
    "            answers = answers + answer_tmp\n",
    "\n",
    "        prompt_vote = input_prompt.format(input_description = symptom, input_answers = answers)\n",
    "        response = timer_llm(prompt_vote, if_print = 0)\n",
    "        result = response[response.index('\\n')+1:]\n",
    "        if  '<answer>' in result and '</answer>' in result:\n",
    "            answer = result[result.index('<answer>')+7:result.index('</answer>')].replace('\\n','').replace('>','')\n",
    "        else:   \n",
    "            answer = result\n",
    "        if  '<reasoning>' in result and '</reasoning>' in result:\n",
    "            reasoning = result[result.index('<reasoning>')+11:result.index('</reasoning>')].replace('\\n','').replace('>','')\n",
    "        else:   \n",
    "            reasoning = 'tbd'\n",
    "        #print(answer)\n",
    "        #print(reasoning)\n",
    "        \n",
    "        gt = symptom = df.iloc[i][1]\n",
    "        if gt in answer:\n",
    "            pred = 'T'\n",
    "        else:\n",
    "            pred = 'F'\n",
    "\n",
    "        df.iat[i,2] = answer\n",
    "        df.iat[i,3] = reasoning\n",
    "        df.iat[i,4] = pred\n",
    "    # save results\n",
    "    df.to_csv(output_file_name,index = False)\n",
    "    return df\n",
    "\n",
    "# Func used to calculate Accuracy\n",
    "# data: df containing test results\n",
    "def accuracy(data):\n",
    "    correct = (data['预测结果'] == 'T').sum()\n",
    "    total = len(data)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d531b7-0243-4321-af90-7399ec490183",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_modifier = {'max_tokens_to_sample':4096, \n",
    "                      \"temperature\":0,\n",
    "                      \"top_k\":250,\n",
    "                      \"top_p\":1,\n",
    "                      \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "                     }\n",
    "\n",
    "textgen_llm = Bedrock(model_id = \"anthropic.claude-v2\",\n",
    "                    client = boto3_bedrock, \n",
    "                    model_kwargs = inference_modifier \n",
    "                    )\n",
    "\n",
    "# adjust your output file name, for example: heather_test_results_base.csv\n",
    "df_base = mybatchtest(raw, p_base, 'REPLACE_YOUR_NAME_HERE_test_results_base.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6612be-8165-4290-a57c-4ca639baeca5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step5: Analyze Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bde3c4-78ae-437e-9af5-24130abf5482",
   "metadata": {},
   "source": [
    "Calculate the accuracy, this is going to be our base.\n",
    "You will probably get pumped since the results looked very promising, and keep in mind that this could be a result of overfitting since our test data size is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7dd132-9f7e-4b92-9a80-a8babeca19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy\n",
    "acc_base = accuracy(df_base)\n",
    "print('Accuracy Base:', acc_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdafdb0-067c-4c43-9591-a3282f26d304",
   "metadata": {},
   "source": [
    "Now, analyze the results and select the worst performed classes as the target to improve.  \n",
    "\n",
    "<b>Trick: <br></b>\n",
    "1, It may be a very good idea to take a closer look at the bad cases and think what may be the reason.<br>\n",
    "2, You may also want to look at multiple classes together, since the problem may be that Claude is having difficulties differentiating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8dc265-ba1f-42fa-a50f-e5992f6e4e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check accuracy by categories\n",
    "df_base.groupby('故障分类').apply(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c432c-6d58-4464-a1f9-572310ed8e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtered out all the cases that have been incorrectly classified\n",
    "df_incorrect_cases = df_base[df_base['预测结果'] == 'F']\n",
    "df_incorrect_cases.describe()\n",
    "\n",
    "examples = ''\n",
    "for i in range(df_incorrect_cases.shape[0]):\n",
    "    symptom = df_incorrect_cases.iloc[i][0]\n",
    "    gt = df_incorrect_cases.iloc[i][1]\n",
    "    pred = df_incorrect_cases.iloc[i][2].replace('>','')\n",
    "    reasoning = df_incorrect_cases.iloc[i][3]\n",
    "    eg_tmp = 'id' + str(i) +':\\n' + '问题描述： ' + symptom + '\\n' + '正确分类： ' + gt + '\\n' + '预测分类： ' + pred + '\\n' + '预测分析： ' + reasoning + '\\n\\n' \n",
    "    examples = examples + eg_tmp\n",
    "df_base_incorrect_cases = examples\n",
    "print(df_base_incorrect_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b8149-3ff6-405e-9bb6-163621508152",
   "metadata": {},
   "source": [
    "### Step6: Improve Prompt and Re-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce99b0-51ce-4c80-931e-2906f5c8f421",
   "metadata": {},
   "source": [
    "#### <font color=\"purple\">Using Claude to Generate Insights About the Results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51c6e3-0b0b-40aa-bcad-7e77b30d06fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_instructions ='''\n",
    "1， 将问题描述分类到以下8个类别中\n",
    "(A) 备件/商务咨询: 提到物品价格,搬迁,流程等与商务有关的问题。\n",
    "(B) 床: 提到床无法移动,出入不便等与床操作相关的问题。\n",
    "(C) 扫描架: 提到gantry, revolution等与扫描架相关的关键词。\n",
    "(D) 扫描问题: 提到无法获得图像,出现伪影,硬件错误等直接与扫描质量相关的问题。\n",
    "(E) 探测器: 提到探测器温度,指针移动产生假影等与探测器相关的问题。\n",
    "(F) 操作台: 提到开机失败,工作站不能使用,传不进PACS等与操作台相关的问题。\n",
    "(G) 球管/高压: 提到球管故障,报错,异响等与球管和高压相关的问题。\n",
    "(H) 无法判断: 对于一些语句信息不足无法判断分类的问题。\n",
    "2，每个问题只选择一个最适合的类别\n",
    "3，如果无法判断类别,则选择“无法判断”\n",
    "'''\n",
    "\n",
    "# This prompt is used to generate insights and rules\n",
    "p_insights = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要按照故障分类要求<instructions>定位客户问题描述中的故障类型。<incorrect_examples>中是一些错分的例子，请分析分类错误可能的原因写入<insights>并将建议添加的分类要求写入<suggested_instructions>。\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "{input_original_instructions}\n",
    "<instructions>\n",
    "\n",
    "<incorrect_examples>中是错分的例子：\n",
    "<incorrect_examples>\n",
    "{input_incorrect_cases}\n",
    "</incorrect_examples>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "<insights>可能导致分类错误的原因</insights>\n",
    "<suggested_instructions>建议添加的分类要求</suggested_instructions>\n",
    "'''\n",
    "\n",
    "prompt = p_insights.format(input_original_instructions = original_instructions, input_incorrect_cases = incorrect_cases)\n",
    "response = timer_llm(prompt)\n",
    "result = response[response.index('\\n')+1:]\n",
    "print_ww(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72fbd7-bd49-4c93-82a7-409a4b2ff4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add the suggested instructions in your base prompt, and use it to re-do batch testing\n",
    "# below is an example\n",
    "p_base_add_suggested_instructions_example = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要根据分类要求<instructions>对客户的描述<description>对客服问题进行分类。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{input_description}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "1， 将上方<description>中描述的客服问题分类到以下8个类别中\n",
    "备件/商务咨询: 提到物品价格,搬迁,流程等与商务有关的问题。\n",
    "床: 提到床无法移动,出入不便等与床操作相关的问题。\n",
    "扫描架: 提到gantry, revolution等与扫描架相关的关键词。\n",
    "扫描问题: 提到无法获得图像,出现伪影,硬件错误等直接与扫描质量相关的问题。\n",
    "探测器: 提到探测器温度,指针移动产生假影等与探测器相关的问题。\n",
    "操作台: 提到开机失败,工作站不能使用,传不进PACS等与操作台相关的问题。\n",
    "球管/高压: 提到球管故障,报错,异响等与球管和高压相关的问题。\n",
    "无法判断: 对于一些语句信息不足无法判断分类的问题。\n",
    "2，每个问题只选择一个最适合的类别\n",
    "3，如果无法判断类别,则选择“无法判断”\n",
    "4， 明确定义分类中使用的关键词,例如扫描仪指代整台设备,扫描架特指gantry部分。\n",
    "5，注意问题描述的整体语义,不要过度依赖某些关键词进行分类。\n",
    "6，进一步明确各分类类别的区分标准,避免分类混淆。\n",
    "7，对信息不足无法判断类别的问题,不要强行分类,选择“无法判断”。\n",
    "8，对包含多个类别关键词的问题描述,选择最相关的一个类别进行分类。\n",
    "9， 必须严格用<example>中给出的样例格式回复, 输出结果中必须包含：<answer></answer>和<reasoning></reasoning>：\n",
    "<example>\n",
    "<answer>：\n",
    "操作台\n",
    "</answer>\n",
    "<reasoning>：\n",
    "根据分类规则工作站不能使用，死机，黑屏属于操作台故障分类。\n",
    "</reasoning>：\n",
    "</example>\n",
    "<instructions>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "<answer>分类结果</answer>\n",
    "<reasoning>分析</reasoning>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163ac7b-ebc6-4e83-a5ce-5fef33e2c62c",
   "metadata": {},
   "source": [
    "#### Now write your own prompt <br>\n",
    "\n",
    "<b>Requirements: </b><br>\n",
    "1, Put classification answer into \"\\<answer>\\</answer>\" tags in the response <br>\n",
    "2, Put reasoning into \"\\<reasoning>\\</reasoning>\" tags in the response <br>\n",
    "3, <b><font color=green>Adding suggested instructions from previous step into your base prompt</b><br>\n",
    "<b><font color=red> !Note that you may need to change below functions if your own prompts have different output formats to the examples given!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34300ea8-03c3-4f59-8980-fd627cca1fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now write your own prompt\n",
    "p_base_add_suggested_instructions = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要根据分类要求<instructions>对客户的描述<description>对客服问题进行分类。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{{PLACEHOLDER FOR INPUT DESCRIPTION}}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "{{YOUR OWN INSTRUCTIONS}}\n",
    "</instructions>\n",
    "\n",
    "<output_format>中是输出格式要求：\n",
    "<output_format>\n",
    "{{REQUIREMENTS/EXAMPLES FOR OUTPUT FORMAT}}\n",
    "</output_format>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "# adjust your output file name, for example: heather_test_results_base_add_suggested_instructions.csv\n",
    "df_base_add_suggested_instructions = mybatchtest(raw, p_base_add_suggested_instructions, 'REPLACE_YOUR_NAME_HERE__test_results_base_add_suggested_instructions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28acd6d2-1636-4fa5-9058-0410b3de3f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check results\n",
    "acc_base_add_suggested_instructions = accuracy(df_base_add_suggested_instructions)\n",
    "print('Accuracy with Suggested Instructions:', acc_base_add_suggested_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de9097-5dbb-469a-a3e1-021347a0cf6b",
   "metadata": {},
   "source": [
    "#### <font color=\"purple\">Adding Few-Shots Examples</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb791291-ea56-4a9d-9875-7be17388d9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtered out all the cases that have originally been incorrectly classified, and take a sample of 50%.\n",
    "# Notice that you should lower this rate with larger test dataset to avoid overfitting\n",
    "df_incorrect_cases = df_base[df_base['预测结果'] == 'F']\n",
    "df_incorrect_cases_sample = df_incorrect_cases.groupby(\"故障分类\").sample(frac = 0.5, random_state=1)\n",
    "df_incorrect_cases_sample.groupby('故障分类').count()\n",
    "print(df_incorrect_cases_sample.describe())\n",
    "\n",
    "examples = ''\n",
    "for i in range(df_incorrect_cases_sample.shape[0]):\n",
    "    symptom = df_incorrect_cases_sample.iloc[i][0]\n",
    "    gt = df_incorrect_cases_sample.iloc[i][1]\n",
    "    eg_tmp = 'id' + str(i) +':\\n' + '问题描述： ' + symptom + '\\n' + '正确分类： ' + gt + '\\n\\n' \n",
    "    examples = examples + eg_tmp\n",
    "incorrect_cases_sample = examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3cfb8-eab7-47e8-9365-9023184a8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the base prompt and the sampled bad cases into one prompt, and use it to re-do batch testing\n",
    "# below is an example\n",
    "# combine the base prompt and the sampled bad cases into one prompt, and use it to re-do batch testing\n",
    "p_base_add_few_shots_1 = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要根据分类要求<instructions>对客户的描述<description>对客服问题进行分类。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{input_description}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "1， 将上方<description>中描述的客服问题分类到以下8个类别中\n",
    "备件/商务咨询: 提到物品价格,搬迁,流程等与商务有关的问题。\n",
    "床: 提到床无法移动,出入不便等与床操作相关的问题。\n",
    "扫描架: 提到gantry, revolution等与扫描架相关的关键词。\n",
    "扫描问题: 提到无法获得图像,出现伪影,硬件错误等直接与扫描质量相关的问题。\n",
    "探测器: 提到探测器温度,指针移动产生假影等与探测器相关的问题。\n",
    "操作台: 提到开机失败,工作站不能使用,传不进PACS等与操作台相关的问题。\n",
    "球管/高压: 提到球管故障,报错,异响等与球管和高压相关的问题。\n",
    "无法判断: 对于一些语句信息不足无法判断分类的问题。\n",
    "2，每个问题只选择一个最适合的类别\n",
    "3，如果无法判断类别,则选择“无法判断”\n",
    "4， 必须严格用<example>中给出的样例格式回复, 输出结果中必须包含：<answer></answer>和<reasoning></reasoning>：\n",
    "<example>\n",
    "<answer>：\n",
    "操作台\n",
    "</answer>\n",
    "<reasoning>：\n",
    "根据分类规则工作站不能使用，死机，黑屏属于操作台故障分类。\n",
    "</reasoning>：\n",
    "</example>\n",
    "<instructions>\n",
    "'''\n",
    "\n",
    "p_base_add_few_shots_2 = '''\n",
    "<examples>中是一些分类例子：\n",
    "<examples>\n",
    "{input_examples}\n",
    "</examples>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "<answer>分类结果</answer>\n",
    "<reasoning>分析</reasoning>\n",
    "'''\n",
    "\n",
    "p_base_add_few_shots_example = p_base_add_few_shots_1 + p_base_add_few_shots_2.format(input_examples = incorrect_cases_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1c6ca-dad2-4b24-962f-fceba7173938",
   "metadata": {},
   "source": [
    "#### Now write your own prompt <br>\n",
    "\n",
    "<b>Requirements: </b><br>\n",
    "1, Put classification answer into \"\\<answer>\\</answer>\" tags in the response <br>\n",
    "2, Put reasoning into \"\\<reasoning>\\</reasoning>\" tags in the response <br>\n",
    "3, <b><font color=green> Adding bad cases in your base prompt (Few-Shots)</b> <br>\n",
    "<b><font color=red> !Note that you may need to change below functions if your own prompts have different output formats to the examples given!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ad352-a1d4-4f76-a71b-24f6d6b80109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now write your own prompt\n",
    "p_base_add_few_shots = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要根据分类要求<instructions>对客户的描述<description>对客服问题进行分类。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{{PLACEHOLDER FOR INPUT DESCRIPTION}}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "{{YOUR OWN INSTRUCTIONS}}\n",
    "</instructions>\n",
    "\n",
    "<output_format>中是输出格式要求：\n",
    "<output_format>\n",
    "{{REQUIREMENTS/EXAMPLES FOR OUTPUT FORMAT}}\n",
    "</output_format>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "\n",
    "# adjust your output file name, for example: heather_test_results_base_add_few_shots.csv\n",
    "df_base_add_few_shots = mybatchtest(raw, p_base_add_few_shots, 'REPLACE_YOUR_NAME_HERE_test_results_base_add_few_shots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ed877-85e8-461b-b23d-56b03601ce6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check results\n",
    "acc_base_add_few_shots = accuracy(df_base_add_few_shots)\n",
    "print('Accuracy with Few-Shots:', acc_base_add_few_shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f6e61-cc31-4016-aecf-e24b46ad7340",
   "metadata": {},
   "source": [
    "#### <font color=\"purple\">Generate Claude Multiple Times and Vote for the Best Answer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18ae55-44b4-4958-971e-eac6ac3fde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt is use to evaluate and vote for the best answer\n",
    "# Notice this cell is going to take resample_times * batch_testing_time \n",
    "# below is an example\n",
    "p_base_vote_example = '''\n",
    "\\n\\nHuman: 您是一个客服复审员，你的任务是对已经做出的客服分类进行复审投票。\n",
    "几名客服人员对<description>中同一个问题描述做出了故障分类的判断，请选出答案中的多数派。\n",
    "如果有多个分类同票或所有答案都不相同，请结合<instructions>中的分类要求和客服人员的分类分析，选出几个答案中最优的一个答案输出。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{input_description}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "1， 将上方<description>中描述的客服问题分类到以下8个类别中\n",
    "(A) 备件/商务咨询: 提到物品价格,搬迁,流程等与商务有关的问题。\n",
    "(B) 床: 提到床无法移动,出入不便等与床操作相关的问题。\n",
    "(C) 扫描架: 提到gantry, revolution等与扫描架相关的关键词。\n",
    "(D) 扫描问题: 提到无法获得图像,出现伪影,硬件错误等直接与扫描质量相关的问题。\n",
    "(E) 探测器: 提到探测器温度,指针移动产生假影等与探测器相关的问题。\n",
    "(F) 操作台: 提到开机失败,工作站不能使用,传不进PACS等与操作台相关的问题。\n",
    "(G) 球管/高压: 提到球管故障,报错,异响等与球管和高压相关的问题。\n",
    "(H) 无法判断: 对于一些语句信息不足无法判断分类的问题。\n",
    "2，每个问题只选择一个最适合的类别\n",
    "3，如果无法判断类别,则选择“无法判断”\n",
    "4，必须严格用<example>中给出的样例格式回复, 输出结果中必须包含：<answer></answer>和<reasoning></reasoning>：\n",
    "<example>\n",
    "<answer>：\n",
    "（F）操作台\n",
    "</answer>\n",
    "<reasoning>：\n",
    "根据分类规则工作站不能使用，死机，黑屏属于操作台故障分类。\n",
    "</reasoning>：\n",
    "</example>\n",
    "<instructions>\n",
    "\n",
    "<answers>中是来自多个客服人员的分类：\n",
    "<answers>\n",
    "{input_answers}\n",
    "</answers>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "<answer>最终结果</answer>\n",
    "<reasoning>分析</reasoning>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a77b4b-a1a8-4a3b-b160-96071698e126",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Now write your own prompt <br>\n",
    "\n",
    "<b>Requirements: </b><br>\n",
    "1, Put classification answer into \"\\<answer>\\</answer>\" tags in the response <br>\n",
    "2, Put reasoning into \"\\<reasoning>\\</reasoning>\" tags in the response <br>\n",
    "3, <b><font color=green>Here the task is to evaluate several results and vote for the best</b> <br>\n",
    "<b><font color=red> !Note that you may need to change below functions if your own prompts have different output formats to the examples given!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b176dbd-c75e-40de-a6e8-6136e035dbbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now write your own prompt\n",
    "p_base_vote = '''\n",
    "\\n\\nHuman: 您是一个客服代表,需要根据分类要求<instructions>对客户的描述<description>对客服问题进行分类。\n",
    "\n",
    "<description>中是问题描述：\n",
    "<description>\n",
    "{{PLACEHOLDER FOR INPUT DESCRIPTION}}\n",
    "</description>\n",
    "\n",
    "<instructions>中是分类要求：\n",
    "<instructions>\n",
    "{{YOUR OWN INSTRUCTIONS}}\n",
    "</instructions>\n",
    "\n",
    "<output_format>中是输出格式要求：\n",
    "<output_format>\n",
    "{{REQUIREMENTS/EXAMPLES FOR OUTPUT FORMAT}}\n",
    "</output_format>\n",
    "\n",
    "\\n\\nAssistant:\n",
    "'''\n",
    "\n",
    "# adjust your output file name, for example: heather_test_results_base_vote.csv\n",
    "df_base_vote = mybatchtest_resample(raw, p_base, p_base_vote, 'REPLACE_YOUR_NAME_HERE_test_results_base_vote.csv', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a50ac-431d-415e-bd20-4793592fdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "acc_base_vote = accuracy(df_base_vote)\n",
    "print('Accuracy with Evaluation and Votting:', acc_base_vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f9cc0-256b-4112-9e1c-bb8ab7b666f4",
   "metadata": {},
   "source": [
    "# <font color=red>Assignment: Write down Your Final Prompt and Copy it to the Quip<font color=red>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
